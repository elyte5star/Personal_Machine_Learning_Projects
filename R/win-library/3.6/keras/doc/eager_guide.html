<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1">



<title>Keras with Eager Execution</title>



<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>



<style type="text/css">body {
background-color: #fff;
margin: 1em auto;
max-width: 700px;
overflow: visible;
padding-left: 2em;
padding-right: 2em;
font-family: "Open Sans", "Helvetica Neue", Helvetica, Arial, sans-serif;
font-size: 14px;
line-height: 1.35;
}
#header {
text-align: center;
}
#TOC {
clear: both;
margin: 0 0 10px 10px;
padding: 4px;
width: 400px;
border: 1px solid #CCCCCC;
border-radius: 5px;
background-color: #f6f6f6;
font-size: 13px;
line-height: 1.3;
}
#TOC .toctitle {
font-weight: bold;
font-size: 15px;
margin-left: 5px;
}
#TOC ul {
padding-left: 40px;
margin-left: -1.5em;
margin-top: 5px;
margin-bottom: 5px;
}
#TOC ul ul {
margin-left: -2em;
}
#TOC li {
line-height: 16px;
}
table {
margin: 1em auto;
border-width: 1px;
border-color: #DDDDDD;
border-style: outset;
border-collapse: collapse;
}
table th {
border-width: 2px;
padding: 5px;
border-style: inset;
}
table td {
border-width: 1px;
border-style: inset;
line-height: 18px;
padding: 5px 5px;
}
table, table th, table td {
border-left-style: none;
border-right-style: none;
}
table thead, table tr.even {
background-color: #f7f7f7;
}
p {
margin: 0.5em 0;
}
blockquote {
background-color: #f6f6f6;
padding: 0.25em 0.75em;
}
hr {
border-style: solid;
border: none;
border-top: 1px solid #777;
margin: 28px 0;
}
dl {
margin-left: 0;
}
dl dd {
margin-bottom: 13px;
margin-left: 13px;
}
dl dt {
font-weight: bold;
}
ul {
margin-top: 0;
}
ul li {
list-style: circle outside;
}
ul ul {
margin-bottom: 0;
}
pre, code {
background-color: #f7f7f7;
border-radius: 3px;
color: #333;
white-space: pre-wrap; 
}
pre {
border-radius: 3px;
margin: 5px 0px 10px 0px;
padding: 10px;
}
pre:not([class]) {
background-color: #f7f7f7;
}
code {
font-family: Consolas, Monaco, 'Courier New', monospace;
font-size: 85%;
}
p > code, li > code {
padding: 2px 0px;
}
div.figure {
text-align: center;
}
img {
background-color: #FFFFFF;
padding: 2px;
border: 1px solid #DDDDDD;
border-radius: 3px;
border: 1px solid #CCCCCC;
margin: 0 5px;
}
h1 {
margin-top: 0;
font-size: 35px;
line-height: 40px;
}
h2 {
border-bottom: 4px solid #f7f7f7;
padding-top: 10px;
padding-bottom: 2px;
font-size: 145%;
}
h3 {
border-bottom: 2px solid #f7f7f7;
padding-top: 10px;
font-size: 120%;
}
h4 {
border-bottom: 1px solid #f7f7f7;
margin-left: 8px;
font-size: 105%;
}
h5, h6 {
border-bottom: 1px solid #ccc;
font-size: 105%;
}
a {
color: #0033dd;
text-decoration: none;
}
a:hover {
color: #6666ff; }
a:visited {
color: #800080; }
a:visited:hover {
color: #BB00BB; }
a[href^="http:"] {
text-decoration: underline; }
a[href^="https:"] {
text-decoration: underline; }

code > span.kw { color: #555; font-weight: bold; } 
code > span.dt { color: #902000; } 
code > span.dv { color: #40a070; } 
code > span.bn { color: #d14; } 
code > span.fl { color: #d14; } 
code > span.ch { color: #d14; } 
code > span.st { color: #d14; } 
code > span.co { color: #888888; font-style: italic; } 
code > span.ot { color: #007020; } 
code > span.al { color: #ff0000; font-weight: bold; } 
code > span.fu { color: #900; font-weight: bold; }  code > span.er { color: #a61717; background-color: #e3d2d2; } 
</style>




</head>

<body>




<h1 class="title toc-ignore">Keras with Eager Execution</h1>



<p>Eager execution is a way to train a Keras model without building a graph. Operations return values, not tensors. Consequently, you can inspect what goes in and comes out of an operation simply by printing a variable’s contents. This is an important advantage in model development and debugging.</p>
<p>You can use eager execution with Keras as long as you use the TensorFlow implementation. This guide gives an outline of the workflow by way of a simple regression example. Specifically, you will see how to:</p>
<ul>
<li>Set up your environment for eager execution</li>
<li>Define the main ingredients: a Keras model, an optimizer and a loss function</li>
<li>Feed data to the training routine</li>
<li>Write a simple training loop that does backprop on the model’s weights</li>
<li>Make predictions on the test set</li>
<li>Save the model’s weights</li>
</ul>
<div id="requirements" class="section level2">
<h2>Requirements</h2>
<p>To use eager execution with Keras, you need a current version of the R package <code>keras</code> with a TensorFlow backend of version at least 1.9.</p>
<p>The following preamble is required when using eager execution:</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb1-1" data-line-number="1"><span class="kw">library</span>(keras)</a>
<a class="sourceLine" id="cb1-2" data-line-number="2"><span class="co"># make sure we use the tensorflow implementation of Keras</span></a>
<a class="sourceLine" id="cb1-3" data-line-number="3"><span class="co"># this line has to be executed immediately after loading the library</span></a>
<a class="sourceLine" id="cb1-4" data-line-number="4"><span class="kw">use_implementation</span>(<span class="st">&quot;tensorflow&quot;</span>)</a>
<a class="sourceLine" id="cb1-5" data-line-number="5"></a>
<a class="sourceLine" id="cb1-6" data-line-number="6"><span class="kw">library</span>(tensorflow)</a>
<a class="sourceLine" id="cb1-7" data-line-number="7"><span class="co"># enable eager execution</span></a>
<a class="sourceLine" id="cb1-8" data-line-number="8"><span class="co"># the argument device_policy is needed only when using a GPU</span></a>
<a class="sourceLine" id="cb1-9" data-line-number="9"><span class="kw">tfe_enable_eager_execution</span>(<span class="dt">device_policy =</span> <span class="st">&quot;silent&quot;</span>)</a></code></pre></div>
<p>When in doubt, check if you are in fact using eager execution:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb2-1" data-line-number="1">tf<span class="op">$</span><span class="kw">executing_eagerly</span>()</a></code></pre></div>
</div>
<div id="define-a-model" class="section level2">
<h2>Define a model</h2>
<p>Models for use with eager execution are defined as Keras <a href="https://tensorflow.rstudio.com/keras/articles/custom_models.html">custom models</a>.</p>
<p>Custom models are usually made up of normal Keras layers, which you configure as usual. However, you are free to implement custom logic in the model’s (implicit) <em>call</em> function.</p>
<p>Our simple regression example will use <code>iris</code> to predict <code>Sepal.Width</code> from <code>Petal.Length</code>, <code>Sepal.Length</code> and <code>Petal.Width</code>.</p>
<p>Here is a model that can be used for that purpose:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb3-1" data-line-number="1"><span class="co"># model instantiator </span></a>
<a class="sourceLine" id="cb3-2" data-line-number="2">iris_regression_model &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">name =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb3-3" data-line-number="3">  </a>
<a class="sourceLine" id="cb3-4" data-line-number="4">  <span class="kw">keras_model_custom</span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {</a>
<a class="sourceLine" id="cb3-5" data-line-number="5">    </a>
<a class="sourceLine" id="cb3-6" data-line-number="6">    <span class="co"># define any number of layers here</span></a>
<a class="sourceLine" id="cb3-7" data-line-number="7">    self<span class="op">$</span>dense1 &lt;-<span class="st"> </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">32</span>)</a>
<a class="sourceLine" id="cb3-8" data-line-number="8">    self<span class="op">$</span>dropout &lt;-<span class="st"> </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb3-9" data-line-number="9">    self<span class="op">$</span>dense2 &lt;-<span class="st"> </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb3-10" data-line-number="10">    </a>
<a class="sourceLine" id="cb3-11" data-line-number="11">    <span class="co"># this is the &quot;call&quot; function that defines what happens when the model is called</span></a>
<a class="sourceLine" id="cb3-12" data-line-number="12">    <span class="cf">function</span> (x, <span class="dt">mask =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb3-13" data-line-number="13">      x <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb3-14" data-line-number="14"><span class="st">        </span>self<span class="op">$</span><span class="kw">dense1</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb3-15" data-line-number="15"><span class="st">        </span>self<span class="op">$</span><span class="kw">dropout</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb3-16" data-line-number="16"><span class="st">        </span>self<span class="op">$</span><span class="kw">dense2</span>()</a>
<a class="sourceLine" id="cb3-17" data-line-number="17">    }</a>
<a class="sourceLine" id="cb3-18" data-line-number="18">  })</a>
<a class="sourceLine" id="cb3-19" data-line-number="19">}</a></code></pre></div>
<p>The model is created simply by instantiating it via its wrapper:</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb4-1" data-line-number="1">model &lt;-<span class="st"> </span><span class="kw">iris_regression_model</span>()</a></code></pre></div>
<p>At this point, the shapes of the model’s weights are still unknown (note how no <code>input_shape</code> has been defined for its first layer). You can, however, already call the model on some dummy data:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb5-1" data-line-number="1"><span class="kw">model</span>(<span class="kw">k_constant</span>(<span class="kw">matrix</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">6</span>, <span class="dt">nrow =</span> <span class="dv">2</span>, <span class="dt">ncol =</span> <span class="dv">3</span>)))</a></code></pre></div>
<pre><code>tf.Tensor(
[[-1.1474639]
 [-1.0472134]], shape=(2, 1), dtype=float32)</code></pre>
<p>After that call, you can inspect the model’s weights using</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb7-1" data-line-number="1">model<span class="op">$</span>weights</a></code></pre></div>
<p>This will not just display the tensor shapes, but the actual weight values.</p>
</div>
<div id="losses-and-optimizers" class="section level2">
<h2>Losses and optimizers</h2>
<p>An appropriate loss function for a regression task like this is mean squared error:</p>
<div class="sourceCode" id="cb8"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb8-1" data-line-number="1">mse_loss &lt;-<span class="st"> </span><span class="cf">function</span>(y_true, y_pred, x) {</a>
<a class="sourceLine" id="cb8-2" data-line-number="2">  <span class="co"># it's required to use a TensorFlow function here, not loss_mean_squared_error() from Keras</span></a>
<a class="sourceLine" id="cb8-3" data-line-number="3">  mse &lt;-<span class="st"> </span>tf<span class="op">$</span>losses<span class="op">$</span><span class="kw">mean_squared_error</span>(y_true, y_pred)</a>
<a class="sourceLine" id="cb8-4" data-line-number="4">  <span class="co"># here you could compute and add other losses </span></a>
<a class="sourceLine" id="cb8-5" data-line-number="5">  mse</a>
<a class="sourceLine" id="cb8-6" data-line-number="6">}</a></code></pre></div>
<p>Note how we have to use loss functions from TensorFlow, not the Keras equivalents. In the same vein, we need to use an optimizer from the <code>tf$train</code> module.</p>
<div class="sourceCode" id="cb9"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb9-1" data-line-number="1"><span class="co"># have to use an optimizer from tf$train, not Keras</span></a>
<a class="sourceLine" id="cb9-2" data-line-number="2">optimizer &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">AdamOptimizer</span>()</a></code></pre></div>
</div>
<div id="use-tfdatasets-to-feed-the-data" class="section level2">
<h2>Use tfdatasets to feed the data</h2>
<p>In eager execution, you use <a href="https://tensorflow.rstudio.com/tools/tfdatasets">tfdatasets</a> to stream input and target data to the model. In our simple <code>iris</code> example, we use <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/tensor_slices_dataset.html">tensor_slices_dataset</a> to directly create a dataset from the underlying R matrices <code>x_train</code> and <code>y_train</code>.</p>
<p>However, a wide variety of other <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/#section-creating-datasets">dataset creation</a> functions is available. Datasets also allow for a variety of pre-processing <a href="https://tensorflow.rstudio.com/tools/tfdatasets/reference/#section-transforming-datasets">transformations</a>.</p>
<div class="sourceCode" id="cb10"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb10-1" data-line-number="1">x_train &lt;-</a>
<a class="sourceLine" id="cb10-2" data-line-number="2"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw">c</span>(<span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb10-3" data-line-number="3">y_train &lt;-</a>
<a class="sourceLine" id="cb10-4" data-line-number="4"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw">c</span>(<span class="st">&quot;Sepal.Width&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb10-5" data-line-number="5"></a>
<a class="sourceLine" id="cb10-6" data-line-number="6"><span class="co"># Convert to approriate tensor floating point type for backend</span></a>
<a class="sourceLine" id="cb10-7" data-line-number="7">x_train &lt;-<span class="st"> </span><span class="kw">k_constant</span>(x_train)</a>
<a class="sourceLine" id="cb10-8" data-line-number="8">y_train &lt;-<span class="st"> </span><span class="kw">k_constant</span>(y_train)</a>
<a class="sourceLine" id="cb10-9" data-line-number="9"></a>
<a class="sourceLine" id="cb10-10" data-line-number="10"><span class="co"># same for test set</span></a>
<a class="sourceLine" id="cb10-11" data-line-number="11">x_test &lt;-</a>
<a class="sourceLine" id="cb10-12" data-line-number="12"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw">c</span>(<span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb10-13" data-line-number="13">y_test &lt;-</a>
<a class="sourceLine" id="cb10-14" data-line-number="14"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw">c</span>(<span class="st">&quot;Sepal.Width&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb10-15" data-line-number="15">x_test &lt;-<span class="st"> </span><span class="kw">k_constant</span>(x_test)</a>
<a class="sourceLine" id="cb10-16" data-line-number="16">y_test &lt;-<span class="st"> </span><span class="kw">k_constant</span>(y_test)</a>
<a class="sourceLine" id="cb10-17" data-line-number="17"></a>
<a class="sourceLine" id="cb10-18" data-line-number="18"><span class="kw">library</span>(tfdatasets)</a>
<a class="sourceLine" id="cb10-19" data-line-number="19">train_dataset &lt;-<span class="st"> </span><span class="kw">tensor_slices_dataset</span>(<span class="kw">list</span> (x_train, y_train)) <span class="op">%&gt;%</span><span class="st"> </span></a>
<a class="sourceLine" id="cb10-20" data-line-number="20"><span class="st">  </span><span class="kw">dataset_batch</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb10-21" data-line-number="21">test_dataset &lt;-<span class="st"> </span><span class="kw">tensor_slices_dataset</span>(<span class="kw">list</span> (x_test, y_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb10-22" data-line-number="22"><span class="st">  </span><span class="kw">dataset_batch</span>(<span class="dv">10</span>)</a></code></pre></div>
<p>Data is accessed from a dataset via <code>make_iterator_one_shot</code> (to create an iterator) and <code>iterator_get_next</code> (to obtain the next batch).</p>
<div class="sourceCode" id="cb11"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb11-1" data-line-number="1">iter &lt;-<span class="st"> </span><span class="kw">make_iterator_one_shot</span>(train_dataset)</a>
<a class="sourceLine" id="cb11-2" data-line-number="2">batch &lt;-<span class="st">  </span><span class="kw">iterator_get_next</span>(iter)</a></code></pre></div>
<p>Datasets are available in non-eager (graph) execution as well. However, in eager mode, we can examine the actual values returned from the iterator:</p>
<div class="sourceCode" id="cb12"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb12-1" data-line-number="1">batch</a></code></pre></div>
<pre><code>[[1]]
tf.Tensor(
[[1.4 5.1 0.2]
 [1.4 4.9 0.2]
 [1.3 4.7 0.2]
 [1.5 4.6 0.2]
 [1.4 5.  0.2]
 [1.7 5.4 0.4]
 [1.4 4.6 0.3]
 [1.5 5.  0.2]
 [1.4 4.4 0.2]
 [1.5 4.9 0.1]], shape=(10, 3), dtype=float32)

[[2]]
tf.Tensor(
[[3.5]
 [3. ]
 [3.2]
 [3.1]
 [3.6]
 [3.9]
 [3.4]
 [3.4]
 [2.9]
 [3.1]], shape=(10, 1), dtype=float32)</code></pre>
</div>
<div id="training-loop" class="section level2">
<h2>Training loop</h2>
<p>With eager execution, you take full control over the training process.</p>
<p>In general, you will have at least two loops: an outer loop over epochs, and an inner loop over batches of data returned by the iterator (implemented implicitly by <code>until_out_of_range</code>). The iterator is recreated at the start of each new epoch.</p>
<div class="sourceCode" id="cb14"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb14-1" data-line-number="1">n_epochs &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb14-2" data-line-number="2"></a>
<a class="sourceLine" id="cb14-3" data-line-number="3"><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(n_epochs)) {</a>
<a class="sourceLine" id="cb14-4" data-line-number="4">  </a>
<a class="sourceLine" id="cb14-5" data-line-number="5">  iter &lt;-<span class="st"> </span><span class="kw">make_iterator_one_shot</span>(train_dataset)</a>
<a class="sourceLine" id="cb14-6" data-line-number="6">  total_loss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb14-7" data-line-number="7">  </a>
<a class="sourceLine" id="cb14-8" data-line-number="8">  <span class="kw">until_out_of_range</span>({</a>
<a class="sourceLine" id="cb14-9" data-line-number="9">    </a>
<a class="sourceLine" id="cb14-10" data-line-number="10">    <span class="co"># get a new batch and run forward pass on it </span></a>
<a class="sourceLine" id="cb14-11" data-line-number="11">    </a>
<a class="sourceLine" id="cb14-12" data-line-number="12">    <span class="co"># calculate loss </span></a>
<a class="sourceLine" id="cb14-13" data-line-number="13">    </a>
<a class="sourceLine" id="cb14-14" data-line-number="14">    <span class="co"># calculate gradients of loss w.r.t. model weights</span></a>
<a class="sourceLine" id="cb14-15" data-line-number="15">    </a>
<a class="sourceLine" id="cb14-16" data-line-number="16">    <span class="co"># update model weights</span></a>
<a class="sourceLine" id="cb14-17" data-line-number="17">    </a>
<a class="sourceLine" id="cb14-18" data-line-number="18">  })</a>
<a class="sourceLine" id="cb14-19" data-line-number="19">  </a>
<a class="sourceLine" id="cb14-20" data-line-number="20">  <span class="kw">cat</span>(<span class="st">&quot;Total loss (epoch): &quot;</span>, i, <span class="st">&quot;: &quot;</span>, <span class="kw">as.numeric</span>(total_loss), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb14-21" data-line-number="21">}</a></code></pre></div>
<p>Filling in the missing pieces in the above outline, we will see that</p>
<ul>
<li>Forward propagation is simply a call to <code>model()</code>.</li>
<li>This call has to happen inside the context of a <code>GradientTape</code> that records all operations.</li>
<li>Loss is calculated using the loss function defined before.</li>
<li>From the loss on the one hand and the model’s current weights on the other hand, <code>GradientTape</code> then determines the gradients.</li>
<li>Finally, the optimizer applies the gradients to the weights in its algorithm-specific way.</li>
</ul>
<p>Here is the complete code for the training loop:</p>
<div class="sourceCode" id="cb15"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb15-1" data-line-number="1">n_epochs &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb15-2" data-line-number="2"></a>
<a class="sourceLine" id="cb15-3" data-line-number="3"><span class="co"># loop over epochs</span></a>
<a class="sourceLine" id="cb15-4" data-line-number="4"><span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(n_epochs)) {</a>
<a class="sourceLine" id="cb15-5" data-line-number="5">  </a>
<a class="sourceLine" id="cb15-6" data-line-number="6">  <span class="co"># create fresh iterator from dataset</span></a>
<a class="sourceLine" id="cb15-7" data-line-number="7">  iter &lt;-<span class="st"> </span><span class="kw">make_iterator_one_shot</span>(train_dataset)</a>
<a class="sourceLine" id="cb15-8" data-line-number="8">  </a>
<a class="sourceLine" id="cb15-9" data-line-number="9">  <span class="co"># accumulate current epoch's loss (for display purposes only)</span></a>
<a class="sourceLine" id="cb15-10" data-line-number="10">  total_loss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb15-11" data-line-number="11">  </a>
<a class="sourceLine" id="cb15-12" data-line-number="12">  <span class="co"># loop once through the dataset</span></a>
<a class="sourceLine" id="cb15-13" data-line-number="13">  <span class="kw">until_out_of_range</span>({</a>
<a class="sourceLine" id="cb15-14" data-line-number="14">    </a>
<a class="sourceLine" id="cb15-15" data-line-number="15">    <span class="co"># get next batch</span></a>
<a class="sourceLine" id="cb15-16" data-line-number="16">    batch &lt;-<span class="st">  </span><span class="kw">iterator_get_next</span>(iter)</a>
<a class="sourceLine" id="cb15-17" data-line-number="17">    x &lt;-<span class="st"> </span>batch[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb15-18" data-line-number="18">    y &lt;-<span class="st"> </span>batch[[<span class="dv">2</span>]]</a>
<a class="sourceLine" id="cb15-19" data-line-number="19">    </a>
<a class="sourceLine" id="cb15-20" data-line-number="20">    <span class="co"># forward pass is recorded by tf$GradientTape</span></a>
<a class="sourceLine" id="cb15-21" data-line-number="21">    <span class="kw">with</span>(tf<span class="op">$</span><span class="kw">GradientTape</span>() <span class="op">%as%</span><span class="st"> </span>tape, {</a>
<a class="sourceLine" id="cb15-22" data-line-number="22">     </a>
<a class="sourceLine" id="cb15-23" data-line-number="23">      <span class="co"># run model on current batch</span></a>
<a class="sourceLine" id="cb15-24" data-line-number="24">      preds &lt;-<span class="st"> </span><span class="kw">model</span>(x)</a>
<a class="sourceLine" id="cb15-25" data-line-number="25">     </a>
<a class="sourceLine" id="cb15-26" data-line-number="26">      <span class="co"># compute the loss</span></a>
<a class="sourceLine" id="cb15-27" data-line-number="27">      loss &lt;-<span class="st"> </span><span class="kw">mse_loss</span>(y, preds, x)</a>
<a class="sourceLine" id="cb15-28" data-line-number="28">    })</a>
<a class="sourceLine" id="cb15-29" data-line-number="29">    </a>
<a class="sourceLine" id="cb15-30" data-line-number="30">    <span class="co"># update total loss</span></a>
<a class="sourceLine" id="cb15-31" data-line-number="31">    total_loss &lt;-<span class="st"> </span>total_loss <span class="op">+</span><span class="st"> </span>loss</a>
<a class="sourceLine" id="cb15-32" data-line-number="32">    </a>
<a class="sourceLine" id="cb15-33" data-line-number="33">    <span class="co"># get gradients of loss w.r.t. model weights</span></a>
<a class="sourceLine" id="cb15-34" data-line-number="34">    gradients &lt;-<span class="st"> </span>tape<span class="op">$</span><span class="kw">gradient</span>(loss, model<span class="op">$</span>variables)</a>
<a class="sourceLine" id="cb15-35" data-line-number="35">    </a>
<a class="sourceLine" id="cb15-36" data-line-number="36">    <span class="co"># update model weights</span></a>
<a class="sourceLine" id="cb15-37" data-line-number="37">    optimizer<span class="op">$</span><span class="kw">apply_gradients</span>(</a>
<a class="sourceLine" id="cb15-38" data-line-number="38">      purrr<span class="op">::</span><span class="kw">transpose</span>(<span class="kw">list</span>(gradients, model<span class="op">$</span>variables)),</a>
<a class="sourceLine" id="cb15-39" data-line-number="39">      <span class="dt">global_step =</span> tf<span class="op">$</span>train<span class="op">$</span><span class="kw">get_or_create_global_step</span>()</a>
<a class="sourceLine" id="cb15-40" data-line-number="40">    )</a>
<a class="sourceLine" id="cb15-41" data-line-number="41"></a>
<a class="sourceLine" id="cb15-42" data-line-number="42">  })</a>
<a class="sourceLine" id="cb15-43" data-line-number="43">  </a>
<a class="sourceLine" id="cb15-44" data-line-number="44">  <span class="kw">cat</span>(<span class="st">&quot;Total loss (epoch): &quot;</span>, i, <span class="st">&quot;: &quot;</span>, <span class="kw">as.numeric</span>(total_loss), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb15-45" data-line-number="45">}</a></code></pre></div>
</div>
<div id="predictions-on-the-test-set" class="section level2">
<h2>Predictions on the test set</h2>
<p>Getting predictions on the test set is just a call to <code>model</code>, just like training has been.</p>
<div class="sourceCode" id="cb16"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb16-1" data-line-number="1"><span class="kw">model</span>(x_test)</a></code></pre></div>
</div>
<div id="saving-and-restoring-model-weights" class="section level2">
<h2>Saving and restoring model weights</h2>
<p>To save model weights, create an instance of <code>tf$Checkpoint</code> and pass it the objects to be saved: in our case, the <code>model</code> and the <code>optimizer</code>. This has to happen after the respective objects have been created, but before the training loop.</p>
<div class="sourceCode" id="cb17"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb17-1" data-line-number="1">checkpoint_dir &lt;-<span class="st"> &quot;./checkpoints&quot;</span></a>
<a class="sourceLine" id="cb17-2" data-line-number="2">checkpoint_prefix &lt;-<span class="st"> </span><span class="kw">file.path</span>(checkpoint_dir, <span class="st">&quot;ckpt&quot;</span>)</a>
<a class="sourceLine" id="cb17-3" data-line-number="3">checkpoint &lt;-</a>
<a class="sourceLine" id="cb17-4" data-line-number="4"><span class="st">  </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">Checkpoint</span>(</a>
<a class="sourceLine" id="cb17-5" data-line-number="5">    <span class="dt">optimizer =</span> optimizer,</a>
<a class="sourceLine" id="cb17-6" data-line-number="6">    <span class="dt">model =</span> model</a>
<a class="sourceLine" id="cb17-7" data-line-number="7">  )</a></code></pre></div>
<p>Then at the end of each epoch, you save the model’s current weights, like so:</p>
<div class="sourceCode" id="cb18"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb18-1" data-line-number="1">checkpoint<span class="op">$</span><span class="kw">save</span>(<span class="dt">file_prefix =</span> checkpoint_prefix)</a></code></pre></div>
<p>This call saves model weights only, not the complete graph. Thus on restore, you re-create all components in the same way as above, and then load saved the model weights using e.g.</p>
<div class="sourceCode" id="cb19"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb19-1" data-line-number="1"><span class="co"># restore from recent checkpoint, you can also use a different one</span></a>
<a class="sourceLine" id="cb19-2" data-line-number="2">checkpoint<span class="op">$</span><span class="kw">restore</span>(tf<span class="op">$</span>train<span class="op">$</span><span class="kw">latest_checkpoint</span>(checkpoint_dir))</a></code></pre></div>
<p>You can then obtain predictions from the restored model, on the test set as a whole or batch-wise, using an iterator.</p>
<div class="sourceCode" id="cb20"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb20-1" data-line-number="1"><span class="kw">model</span>(x_test)</a>
<a class="sourceLine" id="cb20-2" data-line-number="2"></a>
<a class="sourceLine" id="cb20-3" data-line-number="3">iter &lt;-<span class="st"> </span><span class="kw">make_iterator_one_shot</span>(test_dataset)</a>
<a class="sourceLine" id="cb20-4" data-line-number="4"><span class="kw">until_out_of_range</span>({</a>
<a class="sourceLine" id="cb20-5" data-line-number="5">  batch &lt;-<span class="st">  </span><span class="kw">iterator_get_next</span>(iter)</a>
<a class="sourceLine" id="cb20-6" data-line-number="6">  preds &lt;-<span class="st"> </span><span class="kw">model</span>(batch[[<span class="dv">1</span>]])</a>
<a class="sourceLine" id="cb20-7" data-line-number="7">  <span class="kw">print</span>(preds)</a>
<a class="sourceLine" id="cb20-8" data-line-number="8">})</a></code></pre></div>
</div>
<div id="complete-example" class="section level2">
<h2>Complete example</h2>
<p>Here is the complete example.</p>
<div class="sourceCode" id="cb21"><pre class="sourceCode r"><code class="sourceCode r"><a class="sourceLine" id="cb21-1" data-line-number="1"><span class="kw">library</span>(keras)</a>
<a class="sourceLine" id="cb21-2" data-line-number="2"><span class="kw">use_implementation</span>(<span class="st">&quot;tensorflow&quot;</span>)</a>
<a class="sourceLine" id="cb21-3" data-line-number="3"></a>
<a class="sourceLine" id="cb21-4" data-line-number="4"><span class="kw">library</span>(tensorflow)</a>
<a class="sourceLine" id="cb21-5" data-line-number="5"><span class="kw">tfe_enable_eager_execution</span>(<span class="dt">device_policy =</span> <span class="st">&quot;silent&quot;</span>)</a>
<a class="sourceLine" id="cb21-6" data-line-number="6"></a>
<a class="sourceLine" id="cb21-7" data-line-number="7"><span class="kw">library</span>(tfdatasets)</a>
<a class="sourceLine" id="cb21-8" data-line-number="8"></a>
<a class="sourceLine" id="cb21-9" data-line-number="9"></a>
<a class="sourceLine" id="cb21-10" data-line-number="10"><span class="co"># Prepare training and test sets ------------------------------------------</span></a>
<a class="sourceLine" id="cb21-11" data-line-number="11"></a>
<a class="sourceLine" id="cb21-12" data-line-number="12">x_train &lt;-</a>
<a class="sourceLine" id="cb21-13" data-line-number="13"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw">c</span>(<span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb21-14" data-line-number="14">x_train &lt;-<span class="st"> </span><span class="kw">k_constant</span>(x_train)</a>
<a class="sourceLine" id="cb21-15" data-line-number="15">y_train &lt;-</a>
<a class="sourceLine" id="cb21-16" data-line-number="16"><span class="st">  </span>iris[<span class="dv">1</span><span class="op">:</span><span class="dv">120</span>, <span class="kw">c</span>(<span class="st">&quot;Sepal.Width&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb21-17" data-line-number="17">y_train &lt;-<span class="st"> </span><span class="kw">k_constant</span>(y_train)</a>
<a class="sourceLine" id="cb21-18" data-line-number="18"></a>
<a class="sourceLine" id="cb21-19" data-line-number="19">x_test &lt;-</a>
<a class="sourceLine" id="cb21-20" data-line-number="20"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw">c</span>(<span class="st">&quot;Petal.Length&quot;</span>, <span class="st">&quot;Sepal.Length&quot;</span>, <span class="st">&quot;Petal.Width&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb21-21" data-line-number="21">x_test &lt;-<span class="st"> </span><span class="kw">k_constant</span>(x_test)</a>
<a class="sourceLine" id="cb21-22" data-line-number="22">y_test &lt;-</a>
<a class="sourceLine" id="cb21-23" data-line-number="23"><span class="st">  </span>iris[<span class="dv">121</span><span class="op">:</span><span class="dv">150</span>, <span class="kw">c</span>(<span class="st">&quot;Sepal.Width&quot;</span>)] <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">as.matrix</span>()</a>
<a class="sourceLine" id="cb21-24" data-line-number="24">y_test &lt;-<span class="st"> </span><span class="kw">k_constant</span>(y_test)</a>
<a class="sourceLine" id="cb21-25" data-line-number="25"></a>
<a class="sourceLine" id="cb21-26" data-line-number="26"></a>
<a class="sourceLine" id="cb21-27" data-line-number="27"></a>
<a class="sourceLine" id="cb21-28" data-line-number="28"><span class="co"># Create datasets for training and testing --------------------------------</span></a>
<a class="sourceLine" id="cb21-29" data-line-number="29"></a>
<a class="sourceLine" id="cb21-30" data-line-number="30">train_dataset &lt;-<span class="st"> </span><span class="kw">tensor_slices_dataset</span>(<span class="kw">list</span> (x_train, y_train)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-31" data-line-number="31"><span class="st">  </span><span class="kw">dataset_batch</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb21-32" data-line-number="32">test_dataset &lt;-<span class="st"> </span><span class="kw">tensor_slices_dataset</span>(<span class="kw">list</span> (x_test, y_test)) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-33" data-line-number="33"><span class="st">  </span><span class="kw">dataset_batch</span>(<span class="dv">10</span>)</a>
<a class="sourceLine" id="cb21-34" data-line-number="34"></a>
<a class="sourceLine" id="cb21-35" data-line-number="35"></a>
<a class="sourceLine" id="cb21-36" data-line-number="36"><span class="co"># Create model ------------------------------------------------------------</span></a>
<a class="sourceLine" id="cb21-37" data-line-number="37"></a>
<a class="sourceLine" id="cb21-38" data-line-number="38">iris_regression_model &lt;-<span class="st"> </span><span class="cf">function</span>(<span class="dt">name =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb21-39" data-line-number="39">  <span class="kw">keras_model_custom</span>(<span class="dt">name =</span> name, <span class="cf">function</span>(self) {</a>
<a class="sourceLine" id="cb21-40" data-line-number="40">    self<span class="op">$</span>dense1 &lt;-<span class="st"> </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">32</span>, <span class="dt">input_shape =</span> <span class="dv">3</span>)</a>
<a class="sourceLine" id="cb21-41" data-line-number="41">    self<span class="op">$</span>dropout &lt;-<span class="st"> </span><span class="kw">layer_dropout</span>(<span class="dt">rate =</span> <span class="fl">0.5</span>)</a>
<a class="sourceLine" id="cb21-42" data-line-number="42">    self<span class="op">$</span>dense2 &lt;-<span class="st"> </span><span class="kw">layer_dense</span>(<span class="dt">units =</span> <span class="dv">1</span>)</a>
<a class="sourceLine" id="cb21-43" data-line-number="43">    </a>
<a class="sourceLine" id="cb21-44" data-line-number="44">    <span class="cf">function</span> (x, <span class="dt">mask =</span> <span class="ot">NULL</span>) {</a>
<a class="sourceLine" id="cb21-45" data-line-number="45">      self<span class="op">$</span><span class="kw">dense1</span>(x) <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-46" data-line-number="46"><span class="st">        </span>self<span class="op">$</span><span class="kw">dropout</span>() <span class="op">%&gt;%</span></a>
<a class="sourceLine" id="cb21-47" data-line-number="47"><span class="st">        </span>self<span class="op">$</span><span class="kw">dense2</span>()</a>
<a class="sourceLine" id="cb21-48" data-line-number="48">    }</a>
<a class="sourceLine" id="cb21-49" data-line-number="49">  })</a>
<a class="sourceLine" id="cb21-50" data-line-number="50">}</a>
<a class="sourceLine" id="cb21-51" data-line-number="51"></a>
<a class="sourceLine" id="cb21-52" data-line-number="52">model &lt;-<span class="st"> </span><span class="kw">iris_regression_model</span>()</a>
<a class="sourceLine" id="cb21-53" data-line-number="53"></a>
<a class="sourceLine" id="cb21-54" data-line-number="54"></a>
<a class="sourceLine" id="cb21-55" data-line-number="55"><span class="co"># Define loss function and optimizer --------------------------------------</span></a>
<a class="sourceLine" id="cb21-56" data-line-number="56"></a>
<a class="sourceLine" id="cb21-57" data-line-number="57">mse_loss &lt;-<span class="st"> </span><span class="cf">function</span>(y_true, y_pred, x) {</a>
<a class="sourceLine" id="cb21-58" data-line-number="58">  mse &lt;-<span class="st"> </span>tf<span class="op">$</span>losses<span class="op">$</span><span class="kw">mean_squared_error</span>(y_true, y_pred)</a>
<a class="sourceLine" id="cb21-59" data-line-number="59">  mse</a>
<a class="sourceLine" id="cb21-60" data-line-number="60">}</a>
<a class="sourceLine" id="cb21-61" data-line-number="61"></a>
<a class="sourceLine" id="cb21-62" data-line-number="62">optimizer &lt;-<span class="st"> </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">AdamOptimizer</span>()</a>
<a class="sourceLine" id="cb21-63" data-line-number="63"></a>
<a class="sourceLine" id="cb21-64" data-line-number="64"></a>
<a class="sourceLine" id="cb21-65" data-line-number="65"><span class="co"># Set up checkpointing ----------------------------------------------------</span></a>
<a class="sourceLine" id="cb21-66" data-line-number="66"></a>
<a class="sourceLine" id="cb21-67" data-line-number="67">checkpoint_dir &lt;-<span class="st"> &quot;./checkpoints&quot;</span></a>
<a class="sourceLine" id="cb21-68" data-line-number="68">checkpoint_prefix &lt;-<span class="st"> </span><span class="kw">file.path</span>(checkpoint_dir, <span class="st">&quot;ckpt&quot;</span>)</a>
<a class="sourceLine" id="cb21-69" data-line-number="69">checkpoint &lt;-</a>
<a class="sourceLine" id="cb21-70" data-line-number="70"><span class="st">  </span>tf<span class="op">$</span>train<span class="op">$</span><span class="kw">Checkpoint</span>(<span class="dt">optimizer =</span> optimizer,</a>
<a class="sourceLine" id="cb21-71" data-line-number="71">                      <span class="dt">model =</span> model)</a>
<a class="sourceLine" id="cb21-72" data-line-number="72"></a>
<a class="sourceLine" id="cb21-73" data-line-number="73">n_epochs &lt;-<span class="st"> </span><span class="dv">10</span></a>
<a class="sourceLine" id="cb21-74" data-line-number="74"></a>
<a class="sourceLine" id="cb21-75" data-line-number="75"><span class="co"># change to TRUE if you want to restore weights</span></a>
<a class="sourceLine" id="cb21-76" data-line-number="76">restore &lt;-<span class="st"> </span><span class="ot">FALSE</span></a>
<a class="sourceLine" id="cb21-77" data-line-number="77"></a>
<a class="sourceLine" id="cb21-78" data-line-number="78"><span class="cf">if</span> (<span class="op">!</span>restore) {</a>
<a class="sourceLine" id="cb21-79" data-line-number="79">  <span class="cf">for</span> (i <span class="cf">in</span> <span class="kw">seq_len</span>(n_epochs)) {</a>
<a class="sourceLine" id="cb21-80" data-line-number="80">    iter &lt;-<span class="st"> </span><span class="kw">make_iterator_one_shot</span>(train_dataset)</a>
<a class="sourceLine" id="cb21-81" data-line-number="81">    total_loss &lt;-<span class="st"> </span><span class="dv">0</span></a>
<a class="sourceLine" id="cb21-82" data-line-number="82">    </a>
<a class="sourceLine" id="cb21-83" data-line-number="83">    <span class="kw">until_out_of_range</span>({</a>
<a class="sourceLine" id="cb21-84" data-line-number="84">      batch &lt;-<span class="st">  </span><span class="kw">iterator_get_next</span>(iter)</a>
<a class="sourceLine" id="cb21-85" data-line-number="85">      x &lt;-<span class="st"> </span>batch[[<span class="dv">1</span>]]</a>
<a class="sourceLine" id="cb21-86" data-line-number="86">      y &lt;-<span class="st"> </span>batch[[<span class="dv">2</span>]]</a>
<a class="sourceLine" id="cb21-87" data-line-number="87">      </a>
<a class="sourceLine" id="cb21-88" data-line-number="88">      <span class="kw">with</span>(tf<span class="op">$</span><span class="kw">GradientTape</span>() <span class="op">%as%</span><span class="st"> </span>tape, {</a>
<a class="sourceLine" id="cb21-89" data-line-number="89">        preds &lt;-<span class="st"> </span><span class="kw">model</span>(x)</a>
<a class="sourceLine" id="cb21-90" data-line-number="90">        loss &lt;-<span class="st"> </span><span class="kw">mse_loss</span>(y, preds, x)</a>
<a class="sourceLine" id="cb21-91" data-line-number="91">      })</a>
<a class="sourceLine" id="cb21-92" data-line-number="92">      </a>
<a class="sourceLine" id="cb21-93" data-line-number="93">      total_loss &lt;-<span class="st"> </span>total_loss <span class="op">+</span><span class="st"> </span>loss</a>
<a class="sourceLine" id="cb21-94" data-line-number="94">      gradients &lt;-<span class="st"> </span>tape<span class="op">$</span><span class="kw">gradient</span>(loss, model<span class="op">$</span>variables)</a>
<a class="sourceLine" id="cb21-95" data-line-number="95">      </a>
<a class="sourceLine" id="cb21-96" data-line-number="96">      optimizer<span class="op">$</span><span class="kw">apply_gradients</span>(purrr<span class="op">::</span><span class="kw">transpose</span>(<span class="kw">list</span>(gradients, model<span class="op">$</span>variables)),</a>
<a class="sourceLine" id="cb21-97" data-line-number="97">                                <span class="dt">global_step =</span> tf<span class="op">$</span>train<span class="op">$</span><span class="kw">get_or_create_global_step</span>())</a>
<a class="sourceLine" id="cb21-98" data-line-number="98">      </a>
<a class="sourceLine" id="cb21-99" data-line-number="99">    })</a>
<a class="sourceLine" id="cb21-100" data-line-number="100">    </a>
<a class="sourceLine" id="cb21-101" data-line-number="101">    <span class="kw">cat</span>(<span class="st">&quot;Total loss (epoch): &quot;</span>, i, <span class="st">&quot;: &quot;</span>, <span class="kw">as.numeric</span>(total_loss), <span class="st">&quot;</span><span class="ch">\n</span><span class="st">&quot;</span>)</a>
<a class="sourceLine" id="cb21-102" data-line-number="102">    </a>
<a class="sourceLine" id="cb21-103" data-line-number="103">    checkpoint<span class="op">$</span><span class="kw">save</span>(<span class="dt">file_prefix =</span> checkpoint_prefix)</a>
<a class="sourceLine" id="cb21-104" data-line-number="104">  }</a>
<a class="sourceLine" id="cb21-105" data-line-number="105">} <span class="cf">else</span> {</a>
<a class="sourceLine" id="cb21-106" data-line-number="106">  checkpoint<span class="op">$</span><span class="kw">restore</span>(tf<span class="op">$</span>train<span class="op">$</span><span class="kw">latest_checkpoint</span>(checkpoint_dir))</a>
<a class="sourceLine" id="cb21-107" data-line-number="107">}</a>
<a class="sourceLine" id="cb21-108" data-line-number="108"></a>
<a class="sourceLine" id="cb21-109" data-line-number="109"></a>
<a class="sourceLine" id="cb21-110" data-line-number="110"><span class="co"># Get model predictions on test set ---------------------------------------</span></a>
<a class="sourceLine" id="cb21-111" data-line-number="111"></a>
<a class="sourceLine" id="cb21-112" data-line-number="112"><span class="kw">model</span>(x_test)</a>
<a class="sourceLine" id="cb21-113" data-line-number="113"></a>
<a class="sourceLine" id="cb21-114" data-line-number="114">iter &lt;-<span class="st"> </span><span class="kw">make_iterator_one_shot</span>(test_dataset)</a>
<a class="sourceLine" id="cb21-115" data-line-number="115"><span class="kw">until_out_of_range</span>({</a>
<a class="sourceLine" id="cb21-116" data-line-number="116">  batch &lt;-<span class="st">  </span><span class="kw">iterator_get_next</span>(iter)</a>
<a class="sourceLine" id="cb21-117" data-line-number="117">  preds &lt;-<span class="st"> </span><span class="kw">model</span>(batch[[<span class="dv">1</span>]])</a>
<a class="sourceLine" id="cb21-118" data-line-number="118">  <span class="kw">print</span>(preds)</a>
<a class="sourceLine" id="cb21-119" data-line-number="119">})</a></code></pre></div>
</div>
<div id="where-to-from-here" class="section level2">
<h2>Where to from here</h2>
<p>In this guide, the task - and consequently, the custom model, associated loss and training routine - have been chosen for their simplicity. Visit the <a href="https://blogs.rstudio.com/tensorflow/">TensorFlow for R blog</a> for case studies and paper implementations that use more intricate custom logic.</p>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
